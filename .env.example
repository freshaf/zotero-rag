# =============================================================================
# Zotero RAG - Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# Lines starting with # are comments.
#
# QUICK START: You only need to fill in the lines marked [REQUIRED].
# Everything else has sensible defaults.
# =============================================================================


# -----------------------------------------------------------------------------
# ZOTERO API [REQUIRED]
# -----------------------------------------------------------------------------
# Get these from https://www.zotero.org/settings/keys
#
# 1. Go to https://www.zotero.org/settings/keys
# 2. Click "Create new private key"
# 3. Give it a name (e.g., "RAG Pipeline")
# 4. Under "Personal Library", check "Allow library access"
# 5. Save and copy the key
#
# Your Library ID is the number shown at:
#   https://www.zotero.org/settings/keys
# (it's labeled "Your userID for use in API calls")

ZOTERO_LIBRARY_ID=your-library-id-here
ZOTERO_API_KEY=your-api-key-here
ZOTERO_LIBRARY_TYPE=user

# (Optional) Index only a specific collection instead of your entire library.
# To find a collection key: right-click a collection in Zotero > "Copy Collection Link"
# The key is the 8-character code at the end of the URL.
# Leave blank to index your entire library.
ZOTERO_COLLECTION_KEY=


# -----------------------------------------------------------------------------
# PINECONE VECTOR DATABASE [REQUIRED]
# -----------------------------------------------------------------------------
# Free tier works fine (up to ~100K chunks).
#
# 1. Sign up at https://app.pinecone.io (free, no credit card needed)
# 2. Create a project
# 3. Go to API Keys and copy your key

PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_INDEX_NAME=zotero-rag


# -----------------------------------------------------------------------------
# EMBEDDING PROVIDER [REQUIRED - choose one]
# -----------------------------------------------------------------------------
# Embeddings convert your text into searchable vectors.
#
# Option A: OpenAI (recommended, ~$0.10 to index 1000 documents)
#   - Fast, high quality
#   - Requires OpenAI API key + small cost
#
# Option B: Ollama (free, runs on your computer)
#   - No cost, fully private
#   - Requires downloading Ollama + a model (~700MB)
#   - Slower for initial indexing

EMBEDDING_PROVIDER=openai

# --- Option A: OpenAI ---
# Get a key at https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# --- Option B: Ollama ---
# Install Ollama from https://ollama.ai, then run: ollama pull nomic-embed-text
# Set EMBEDDING_PROVIDER=ollama above to use this.
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text


# -----------------------------------------------------------------------------
# LLM PROVIDER FOR Q&A (for the web app chat interface)
# -----------------------------------------------------------------------------
# This powers the AI chat in the web app. The search and indexing work
# without an LLM -- you can use search.py with just embeddings.
#
# Option A: OpenAI (recommended for cost -- gpt-4o-mini is ~$0.15/1M tokens)
# Option B: Anthropic Claude (higher quality, higher cost)
# Option C: Ollama (free, runs locally, requires good hardware)

LLM_PROVIDER=openai

# --- Option A: OpenAI (uses the same OPENAI_API_KEY from above) ---
OPENAI_CHAT_MODEL=gpt-4o-mini

# --- Option B: Anthropic ---
# Get a key at https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# --- Option C: Ollama ---
# Install a chat model: ollama pull llama3.1
# Set LLM_PROVIDER=ollama above to use this.
OLLAMA_CHAT_MODEL=llama3.1
